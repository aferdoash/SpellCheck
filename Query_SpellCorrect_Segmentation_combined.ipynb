{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Correction and Text Segmentation\n",
    "\n",
    "### Author : Peter Norvig, Afreen Ferdoash\n",
    "\n",
    "### Prerequisites\n",
    " * Python 2.7\n",
    "\n",
    "### Description\n",
    "This project aims to perform spelling correction and text segmentation on a user query. By spelling correction, we mean predicting the correct word from an incorrectly typed word. By text segmentation, we mean, the ability to parse an incomprehensible word into meaningful words. \n",
    "\n",
    "#### The steps involved in spell-correct are -:\n",
    "1. Read in a large corpus of words\n",
    "2. Count the number of times of appearance of each word\n",
    "3. Generate candidate words from the input word that are -:\n",
    "    1.  Input word itself\n",
    "    2. Words that are 1 edit distance (by way of insert, delete, transpose, replace) away\n",
    "    3. Words that are 2 edit distance (by way of insert, delete, transpose, replace) away\n",
    "4. Find the candidate word with the maximum probability of occurring in the corpus\n",
    "\n",
    "\n",
    "#### The steps involved in text segmenation are -:\n",
    "1. Calculate probability distribution of words in the corpus\n",
    "2. Calculate probability of occurrance of a sequence of words obtained by a candidate segmentation\n",
    "3. Return segmentation which maximizes the above probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\Desktop\\Spell_Correct')\n",
    "\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building word list\n",
    "\n",
    "Text files from the following sources were used to build a list of words and their respective counts of occurance in the corpus.\n",
    "* Project Gutenberg books\n",
    "* Wiktionary (most frequent words)\n",
    "* British National Corpus (most frequent words)\n",
    "* Banking Regulations Manual (Bank of Phillipines)\n",
    "* Banking FAQs (SBI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 33695 \n"
     ]
    }
   ],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = Counter(words(open(r'.\\all_corpus.txt').read()))\n",
    "\n",
    "print \"Total number of unique words: %d \" % len(WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "\n",
    "The input word is first split into possible pairs of words. A set of candidate words are generated from these pairs by performing deletion, transposition, replacement, insertion at edit distance 1 and edit distance 2. The candidates are then checked for their presence in the corpus and that word is chosen which has the maximum probability of occurrance in the corpus. \n",
    "Please note however, that the input word is preferred to candidate words at edit distance 1 which in turn is preferred over candidates at edit distance 2 away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def known(words): return set(w for w in words if w in WORDS)\n",
    "\n",
    "def correction(word):\n",
    "    \"Find the best spelling correction for word.\"\n",
    "    candidates = (known([word]) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORDS.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction with case and punctuation preservation\n",
    "\n",
    "The following is just a minor modification to preserve the case and punctuation in a sentence while performing the spelling correction for each word comprising the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    \"Correct all the words within a text, returning the corrected text.\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    \"Spell-correct word in match, and preserve proper upper/lower/title case.\"\n",
    "    word = match.group()\n",
    "    return case_of(word)(correction(word.lower()))\n",
    "\n",
    "def case_of(text):\n",
    "    \"Return the case-function appropriate for text: upper, lower, title, or just str.\"\n",
    "    return (str.upper if text.isupper() else\n",
    "            str.lower if text.islower() else\n",
    "            str.title if text.istitle() else\n",
    "            str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had lost my debit card....Please help me!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text('I hav lost my dbit crad....Pleeze hlp me!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Segmentation\n",
    "\n",
    "We make a segmentation into a first word and remaining characters. If we assume words are independent then we can maximize the probability of the first word adjoined to the best segmentation of the remaining characters.\n",
    "For this, we first calculate the probability of occurrance of each word in the corpus as the count of its occurance divided by the total number of words in the corpus. For calculating the probability of occurance for a a sequence of words, using the bag of words model assumption, we can compute the product of probability of occurrance of each word in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pdist(counter):\n",
    "    \"Make a probability distribution, given evidence from a Counter.\"\n",
    "    N = sum(counter.values())\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "P = pdist(WORDS)\n",
    "\n",
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower())  \n",
    "\n",
    "def Pwords(words):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product(P(w) for w in words)\n",
    "\n",
    "def product(nums):\n",
    "    \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "    result = 1\n",
    "    for x in nums:\n",
    "        result *= x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    \"Memoize function f, whose args must all be hashable.\"\n",
    "    cache = {}\n",
    "    def fmemo(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = f(*args)\n",
    "        return cache[args]\n",
    "    fmemo.cache = cache\n",
    "    return fmemo\n",
    "\n",
    "def splits(text, start=0, L=20):\n",
    "    \"Return a list of all (first, rest) pairs; start <= len(first) <= L.\"\n",
    "    return [(text[:i], text[i:]) \n",
    "            for i in range(start, min(len(text), L)+1)]\n",
    "\n",
    "@memo\n",
    "def segment(text):\n",
    "    \"Return a list of words that is the most probable segmentation of text.\"\n",
    "    if not text: \n",
    "        return []\n",
    "    else:\n",
    "        candidates = ([first] + segment(rest) \n",
    "                      for (first, rest) in splits(text, 1))\n",
    "        return max(candidates, key=Pwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def segment_text(text):\n",
    "    return re.sub('[a-zA-Z]+', segment_match, text)\n",
    "\n",
    "def segment_match(match):\n",
    "    \"Spell-correct word in match, and preserve proper upper/lower/title case.\"\n",
    "    word = match.group()\n",
    "    return (' '.join(segment(word.lower())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numb', 'r']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('numbr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing both Segmentation and Spell-Correction\n",
    "\n",
    "A Segmentation-first approach worked better than Spell-Correction first approach.Before any text correction, we alter the dictionary of words to retain only the most common one-lettered and two-lettered to avoid 'bad segmentation' (eg. 'numbr' may be segmented to 'numb' + 'r'). \n",
    "We first segment each word of the give text and check if all the words in the segmented output belong to the dictionary. If this is the case, we accept the segmentation and move to the next word. If this is not the case we perform spell-correction on the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twowords = [line.rstrip('\\n') for line in open(r'.\\two-lettered.txt','r+')]\n",
    "onewords = [line.rstrip('\\n') for line in open(r'.\\one-lettered.txt','r+')]\n",
    "allWords = WORDS.keys()\n",
    "allWords = [word for word in allWords if len(word) > 2]\n",
    "allWords = allWords + twowords + onewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performed_correction(word):\n",
    "    segmented= segment(word)\n",
    "    if all(word in allWords for word in segmented ):\n",
    "        ans = ' '.join(segmented) \n",
    "        next\n",
    "    else:        \n",
    "        ans = correction(word)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correction_text(text):\n",
    "    return re.sub('[a-zA-Z]+', correction_match, text)\n",
    "\n",
    "def correction_match(match):\n",
    "    word = match.group()\n",
    "    return performed_correction(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is a cvv number ? '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_text('whatis acvv numbr ? ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
